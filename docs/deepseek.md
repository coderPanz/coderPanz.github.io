<!--
 * @Author: qs
 * @Date: 2025-02-14 17:32:05
 * @LastEditTime: 2025-03-06 19:11:44
 * @LastEditors: qs
 * @Description:
 * @FilePath: /coderPanz.github.io/docs/deepseek.md
 *
-->
  # 为什么 DeepSeek 能一夜爆火？
&emsp; &emsp;2025 开年，相信大家都被deepseek和哪吒二刷屏了，今天我们来聊聊deepseek，他为何会这么火爆。  
  DeepSeek（中文名“深度求索”）是一家专注于实现通用人工智能（AGI）的科技公司，成立于2023年7月，由量化资管巨头幻方量化创立，总部位于中国杭州。该公司致力于开发先进的大语言模型（LLM）及相关技术，并已发布多款高性能AI模型，如DeepSeek-V3、DeepSeek-R1等，这些模型在自然语言处理、推理能力等方面表现出色。  
  &emsp; &emsp; 1 月 20 日，deepseek-R1 模型发布，该模型具备深度思考推理能力的大模型。一经发布，R1 在外网就传疯了。25日特朗普称赞 deepsee创新并宣称这对科技敲醒了警钟，并在27日登顶美国商店免费app榜，然后28日deepseek的线上服务就开始被攻击了，深度思考能力几乎瘫痪，再到后面就是各家企业大厂官宣接入deepseek，360、华为出场为deepseek站台。
在 AI 这片 “兵家必争之地”，一直都有着各种各样的玩家。大家都想在这个领域里分一杯羹，做出点名堂。以前，像 OpenAI 的 GPT 系列这种大模型，那可是行业的 “顶流”，大家都觉得它们厉害得不行不行的。可最近，这个局面被一个叫 DeepSeek 的新玩家给打破了。DeepSeek 就像是一匹 “黑马”，突然之间就火遍了全球科技圈，让所有人都眼前一亮。今天，咱就来好好聊聊，DeepSeek 到底是凭借什么本事，能在高手如云的 AI 领域掀起这么大的风浪。

## 技术创新：DeepSeek 凭本事吃饭

DeepSeek 能火，首先得归功于它在技术上确实有几把刷子。它采用了一种新架构，叫 “混合专家架构（MoE）” 和 “多头潜在注意力（MLA）”。这种架构的好处就是，它能让模型在推理的时候，只用到一小部分参数，而不是像以前那样，所有参数都要一起上阵。这样一来，显存占用和算力需求都大大减少了。

就拿 DeepSeek-V3 来说，它有 6710 亿参数，但推理时只激活 370 亿，这算力消耗一下子降到 GPT-4 的 5%。这就好比以前开车得把所有油门都踩到底才能跑得快，而现在 DeepSeek 只用踩一小部分油门，就能跑得又快又远。

而且，DeepSeek 还用上了 “FP8 混合精度” 和 “MTP” 这些新技术，进一步优化了训练和推理效率。它在训练时，能用更少的资源，成本仅为同类模型的 1/20。这在以前，几乎是不敢想的事情。


DeepSeek 的这种技术创新，直接打破了以往那种靠堆算力来提升模型性能的 “老套路”。它让那些没有豪华硬件的小团队和个人开发者，也能轻松玩转高性能 AI。这就像是给 AI 世界打开了一扇新的大门，让更多的人有机会走进来。

## 开源策略：DeepSeek 的 “朋友圈” 越来越大

DeepSeek 的开源策略也是它成功的一大法宝。它把模型代码和训练方法全都公开了，这让全球的开发者都能参与到它的生态建设中来。

为啥开源这么重要呢？咱来打个比方。以前，那些闭源的大模型就像是一个 “黑箱”，你只能在外面看着它厉害，但里面到底是怎么运作的，你根本不知道。而 DeepSeek 就像是把这个 “黑箱” 打开了，让所有人都能看到里面的构造，还能根据自己的需求去改造它。

这种开源的方式，吸引了大量的开发者。大家都纷纷基于 DeepSeek 的开源代码，开发各种各样的应用。这就像是 DeepSeek 种下了一颗种子，然后开发者们纷纷给它浇水、施肥，让它茁壮成长。截至 2025 年 2 月，已经有 11 家国产 AI 芯片公司完成了对 DeepSeek 模型的适配。


开源还推动了全球 AI 产业的开放化和技术创新。像 Meta 和 Google 这些科技巨头，也纷纷加入到开源阵营中来。这不仅让 DeepSeek 的影响力越来越大，也让整个 AI 社区的氛围更加活跃。

## 市场影响：DeepSeek 挑战行业巨头

DeepSeek 的崛起，对整个 AI 市场都产生了巨大的冲击。它凭借高性能、低成本的优势，迅速在全球范围内获得关注。

在应用场景方面，DeepSeek 已经在自然语言处理、图像生成、文本创作等多个领域取得了显著成果。它的高效生成能力，满足了市场对于内容创作的强烈需求。例如，科研人员可以借助它快速梳理文献综述，创作者能在它的协助下获取新奇的故事灵感，文案工作者则能利用它提升文案的产出效率。


在商业上，DeepSeek 的表现更是抢眼。2025 年 1 月，它的应用成功登顶苹果中美应用商店的免费榜，日活跃用户超过 3000 万，甚至一度超越了 ChatGPT。

DeepSeek 的这种市场表现，直接挑战了行业巨头的地位。它让那些一直占据市场主导地位的公司感到了前所未有的压力。就像 OpenAI 的 CEO 山姆·阿尔特曼说的那样：“DeepSeek 的表现令人印象深刻！”

## 资本与生态：DeepSeek 的 “后台” 很硬

DeepSeek 的背后，也有着强大的资本支持。它的创立者梁文锋是量化对冲基金幻方量化的创始人，幻方量子在量化投资领域有着深厚的技术和资金积累。

而且，DeepSeek 还与 AMD、华为等硬件厂商建立了合作关系。这种合作，不仅保障了 DeepSeek 在硬件资源上的稳定供应，也降低了它对英伟达生态的依赖。


这种资本和硬件的支持，让 DeepSeek 在技术研发和市场竞争中有了更强大的底气。它能够更加专注地去打磨自己的技术，而不必为资金和硬件资源发愁。

DeepSeek 的崛起，不仅仅是技术上的突破，更是整个 AI 生态的一次重构。它让 AI 技术从云端走向本地，从资本密集型行业进入 “草根创业” 领域。

DeepSeek 的故事告诉我们，AI 的未来不仅仅是算力的竞赛，更是算法、架构和生态的竞争。它让我们看到了 AI 技术的更多可能性，也让每一个人都有机会参与到这场 AI 革命中来。

## 众多产品接入deepseek
[目前有哪些主流APP(或平台)接入了DeepSeek-R1？](https://zhuanlan.zhihu.com/p/23601920747)  

首先厘清一个概念，那就是DeepSeek主要有两个版本满血版 vs 蒸馏版：
- 满血版 (671B)：提供最强性能，在复杂逻辑、代码推理、数学解题等方面表现卓越。诸如秘塔AI搜索、NVIDIA NIM、腾讯云等均提供完整版体验​，但运行开销较大，需要强算力支撑。
- 蒸馏版 (小参数)：参数在 1.5B - 70B 不等，牺牲部分精度换取轻量与快速响应。蒸馏版速度快、成本低，但在极复杂问题上偶有力不从心。

目前看来主要有这几类接入了DeepSeek R1。

1. 云服务器上/算力提供商：阿里云、腾讯云、火山引擎、华为云、英伟达、微软等
2. 搜索平台：百度、秘塔ai 搜索、纳米 ai 搜索、知乎问答
3. 集成应用：cursor、通义灵码
3. 智能终端：华为小艺、小爱同学、荣耀 YOYO 助手
其中智能终端估计会比较快的铺开，比如各种电动车等等。
![九号电动车接入deepseek](/九号电动车接入deepseek.png)


## deepseek 试图在绕过英伟达的 curd 架构？
DeepSeek试图绕过英伟达的CUDA架构，但目前尚未完全实现，仍受其限制。DeepSeek试图通过直接操作PTX指令集来绕过CUDA的高层API，进行更细粒度的硬件优化。PTX是CUDA背后的中间指令集，接近硬件层面，允许开发者对GPU的计算资源进行精细的优化。
但最新发现显示，DeepSeek使用英伟达的H800芯片训练时，使用英伟达底层硬件指令PTX（Parallel Thread Execution）语言，而非高级编程语言CUDA。

这样意味着DeepSeek绕过了CUDA，使用更底层的编程语言做优化。

对于程序开发人员来说，CUDA是一种更加友好的高级语言，开发者只需要专注于程序和算法最相关的运行逻辑，而不太需要考虑具体的程序是如何在GPU等硬件上具体如何执行计算的，从而能够降低开发难度。

而PTX在接近汇编语言的层级运行，允许进行细粒度的优化，如寄存器分配和Thread / Warp级别的调整。这种编程非常复杂且难以维护，所以行业通用的做法是使用CUDA这样的高级编程语言。

换句话说，DeepSeek把优化做到了极致。
